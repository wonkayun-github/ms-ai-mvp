import os
import json
import streamlit as st
from dotenv import load_dotenv
from openai import AzureOpenAI
import psycopg2

load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
DEPLOYMENT_NAME = os.getenv("DEPLOYMENT_NAME")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="SW í‰ê°€ ì„¤ë¬¸ì¡°ì‚¬ ë©”íŠ¸ë¦­ êµ¬ì„±",
    page_icon="ğŸ“Š",
    layout="wide"
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "project_searched" not in st.session_state:
    st.session_state.project_searched = False
if "last_project_name" not in st.session_state:
    st.session_state.last_project_name = None
if "all_metrics" not in st.session_state:
    st.session_state.all_metrics = []
if "metrics_generated" not in st.session_state:
    st.session_state.metrics_generated = False

# ì œëª©
st.title("ğŸ“Š ë©”íŠ¸ë¦­ êµ¬ì„±")
st.markdown("**ISO/IEC 25010 í’ˆì§ˆ ì†ì„± ê¸°ë°˜ í‰ê°€ ë©”íŠ¸ë¦­ ì„¤ê³„**")
st.divider()


# DB ì—°ê²° í•¨ìˆ˜
def get_connection():
    """PostgreSQL ì—°ê²°"""
    DB_HOST = os.getenv("PG_HOST")
    DB_NAME = os.getenv("PG_DATABASE")
    DB_USER = os.getenv("PG_USER")
    DB_PASSWORD = os.getenv("PG_PASSWORD")
    DB_PORT = os.getenv("PG_PORT")
    
    return psycopg2.connect(
        host=DB_HOST,
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        port=DB_PORT
    )

# í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ í•¨ìˆ˜
@st.cache_data(ttl=None)
def get_project_list():
    """ì €ì¥ëœ ëª¨ë“  í”„ë¡œì íŠ¸ ì¡°íšŒ"""
    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute("""
            SELECT id, project_name, software_description, created_at 
            FROM surveys 
            ORDER BY created_at DESC
        """)
        projects = cur.fetchall()
        cur.close()
        conn.close()
        return projects
    except Exception as e:
        st.error(f"âŒ í”„ë¡œì íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


# í”„ë¡œì íŠ¸ì˜ ì§ˆë¬¸ ì¡°íšŒ í•¨ìˆ˜
@st.cache_data(ttl=None)
def get_questions_by_project(survey_id):
    """íŠ¹ì • í”„ë¡œì íŠ¸ì˜ ì§ˆë¬¸ ì¡°íšŒ"""
    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute("""
            SELECT id, question_order, quality_attribute, question_text 
            FROM survey_questions 
            WHERE survey_id = %s 
            ORDER BY question_order ASC
        """, (survey_id,))
        questions = cur.fetchall()
        cur.close()
        conn.close()
        return questions
    except Exception as e:
        st.error(f"âŒ ì§ˆë¬¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


# ==================== ë©”ì¸ UI ====================

st.markdown("### ğŸ“‹ 1ë‹¨ê³„: í”„ë¡œì íŠ¸ ì„ íƒ")

projects = get_project_list()

if not projects:
    st.info("â„¹ï¸ ì €ì¥ëœ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì„¤ë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
else:
    col1, col2 = st.columns([8, 2])
    with col1:
        project_options = [f"{p[1]}" for p in projects]
        selected_project_name = st.selectbox(
            "í”„ë¡œì íŠ¸ ì„ íƒ *",
            project_options,
            help="ë©”íŠ¸ë¦­ì„ êµ¬ì„±í•  í”„ë¡œì íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
            key="selected_project"
        )
    with col2:
        st.markdown("<div style='height: 26px'></div>", unsafe_allow_html=True)
        search_button = st.button("ğŸ” ì¡°íšŒ", use_container_width=True, key="search_button")

    if "project_searched" not in st.session_state:
        st.session_state.project_searched = False

    if search_button:
        st.session_state.project_searched = True
    elif selected_project_name != st.session_state.get("last_project_name"):
        st.session_state.project_searched = False

    st.session_state.last_project_name = selected_project_name

    selected_project = next((p for p in projects if p[1] == selected_project_name), None)

    if selected_project and st.session_state.project_searched:
        selected_survey_id = selected_project[0]

        with st.expander("ğŸ“Œ ì„ íƒëœ í”„ë¡œì íŠ¸ ì •ë³´", expanded=True):
            st.markdown(f"**í”„ë¡œì íŠ¸ëª…:** {selected_project[1]}")
            st.markdown(f"**ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ëª…:** {selected_project[2]}")
            st.markdown(f"**ìƒì„± ì¼ì‹œ:** {selected_project[3]}")

        st.divider()
        
        # ì§ˆë¬¸ ì¡°íšŒ
        questions = get_questions_by_project(selected_survey_id)
        
        if questions:
            st.markdown("### ğŸ“ ìƒì„±ëœ ì„¤ë¬¸ì¡°ì‚¬ ì§ˆë¬¸")
            st.markdown(f"**ì´ {len(questions)}ê°œ ì§ˆë¬¸**")
            with st.expander("ì§ˆë¬¸ ëª©ë¡ ë³´ê¸°", expanded=True):
                for q in questions:
                    st.markdown(f"**{q[1]}.** [{q[2]}] {q[3]}")
            
            st.divider()
            
            # ì²™ë„ ì„ íƒ
            st.markdown("### âš–ï¸ 2ë‹¨ê³„: ì²™ë„ ì„ íƒ")
            scale_options = {
                "ë¦¬ì»¤íŠ¸ ì²™ë„ (5ë‹¨ê³„)": "likert_5",
                "ìˆ«ì í‰ì • ì²™ë„ (1~100ì )": "numeric_100"
            }
            selected_scale_name = st.radio(
                "í‰ê°€ ì²™ë„ ì„ íƒ *",
                options=list(scale_options.keys()),
                help="ì„¤ë¬¸ì¡°ì‚¬ì—ì„œ ì‚¬ìš©í•  í‰ê°€ ì²™ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                key="scale_selection"
            )
            selected_scale_type = scale_options[selected_scale_name]
            
            # ì²™ë„ ì„¤ëª…
            if selected_scale_type == "likert_5":
                st.info("ğŸ“Œ **ë¦¬ì»¤íŠ¸ ì²™ë„ (5ë‹¨ê³„)**\n"
                        "- ë§¤ìš° ê·¸ë ‡ì§€ ì•Šë‹¤\n"
                        "- ê·¸ë ‡ì§€ ì•Šë‹¤\n"
                        "- ë³´í†µì´ë‹¤\n"
                        "- ê·¸ë ‡ë‹¤\n"
                        "- ë§¤ìš° ê·¸ë ‡ë‹¤")
            else:
                st.info("ğŸ“Œ **ìˆ«ì í‰ì • ì²™ë„ (1~100ì )**\n"
                        "- ì‘ë‹µìê°€ 1ì ~100ì  ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€\n"
                        "- ë” ì„¸ë¶„í™”ëœ í‰ê°€ ê°€ëŠ¥")
            
            st.divider()

            # ë©”íŠ¸ë¦­ ìƒì„± ë²„íŠ¼
            if st.button("ğŸš€ ë©”íŠ¸ë¦­ ìƒì„±í•˜ê¸°", type="primary", use_container_width=True):
                progress_placeholder = st.empty()
                status_container = st.container()
                
                try:
                    client = AzureOpenAI(
                        azure_endpoint=AZURE_OPENAI_ENDPOINT,
                        api_key=AZURE_OPENAI_API_KEY,
                        api_version="2024-02-15-preview"
                    )
                    
                    progress_placeholder.info("ğŸ”„ ì§ˆë¬¸ë³„ ë©”íŠ¸ë¦­ ìƒì„± ì‹œì‘...")
                    
                    # ì²™ë„ ì„¤ëª…
                    if selected_scale_type == "likert_5":
                        scale_description = """ë¦¬ì»¤íŠ¸ ì²™ë„ (5ë‹¨ê³„):
ë§¤ìš° ê·¸ë ‡ë‹¤
ê·¸ë ‡ë‹¤
ë³´í†µì´ë‹¤
ê·¸ë ‡ì§€ ì•Šë‹¤
ë§¤ìš° ê·¸ë ‡ì§€ ì•Šë‹¤"""
                    else:
                        scale_description = """ìˆ«ì í‰ì • ì²™ê°œ (1~100ì ):
100~81ì : ë§¤ìš° ê¸ì •ì 
80~61ì  : ê¸ì •ì 
60~41ì  : ì¤‘ë¦½
40~21ì  : ë¶€ì •ì 
20~1ì   : ë§¤ìš° ë¶€ì •ì """

                    # ì˜ˆì‹œ JSON
                    if selected_scale_type == "likert_5":
                        example_json = """
ì¶œë ¥ í˜•ì‹(JSON ë°°ì—´, 1ê°œ í•­ëª©):
{
  "question_order": 1,
  "quality_attribute": "ê¸°ëŠ¥ì  ì í•©ì„±",
  "question_text": "ì‹œìŠ¤í…œì€ ìš”êµ¬ëœ ê¸°ëŠ¥ì„ ì •í™•í•˜ê²Œ ìˆ˜í–‰í•˜ëŠ”ê°€?",
  "scale_interpretations": [
    { "scale_order": 5, "scale": "ë§¤ìš° ê·¸ë ‡ë‹¤", "description": "ëª¨ë“  ê¸°ëŠ¥ì´ ì™„ë²½í•˜ê²Œ ìˆ˜í–‰ëœë‹¤." },
    { "scale_order": 4, "scale": "ê·¸ë ‡ë‹¤", "description": "ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ ì •í™•í•˜ê²Œ ìˆ˜í–‰ëœë‹¤." },
    { "scale_order": 3, "scale": "ë³´í†µì´ë‹¤", "description": "ëŒ€ë¶€ë¶„ ìˆ˜í–‰ë˜ì§€ë§Œ ì¼ë¶€ ì˜¤ë¥˜ê°€ ìˆë‹¤." },
    { "scale_order": 2, "scale": "ê·¸ë ‡ì§€ ì•Šë‹¤", "description": "ì¼ë¶€ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤." },
    { "scale_order": 1, "scale": "ë§¤ìš° ê·¸ë ‡ì§€ ì•Šë‹¤", "description": "ìš”êµ¬ëœ ê¸°ëŠ¥ì„ ê±°ì˜ ìˆ˜í–‰í•˜ì§€ ëª»í•œë‹¤." }
  ]
}
"""
                    else:
                        example_json = """
ì¶œë ¥ í˜•ì‹(JSON ë°°ì—´, 1ê°œ í•­ëª©):
{
  "question_order": 1,
  "quality_attribute": "ê¸°ëŠ¥ì  ì í•©ì„±",
  "question_text": "ì‹œìŠ¤í…œì€ ìš”êµ¬ëœ ê¸°ëŠ¥ì„ ì •í™•í•˜ê²Œ ìˆ˜í–‰í•˜ëŠ”ê°€?",
  "scale_interpretations": [
    { "scale_order": 5, "scale": "100~81ì ", "description": "ëª¨ë“  ê¸°ëŠ¥ì´ ì™„ë²½í•˜ê²Œ ìˆ˜í–‰ëœë‹¤." },
    { "scale_order": 4, "scale": "80~61ì ", "description": "ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ ì •í™•í•˜ê²Œ ìˆ˜í–‰ëœë‹¤." },
    { "scale_order": 3, "scale": "60~41ì ", "description": "ì¼ë¶€ ì˜¤ë¥˜ê°€ ìˆìœ¼ë‚˜ ëŒ€ë¶€ë¶„ ìˆ˜í–‰ëœë‹¤." },
    { "scale_order": 2, "scale": "40~21ì ", "description": "ì£¼ìš” ê¸°ëŠ¥ ì¤‘ ì¼ë¶€ê°€ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤." },
    { "scale_order": 1, "scale": "20~1ì ", "description": "ìš”êµ¬ëœ ê¸°ëŠ¥ì„ ê±°ì˜ ìˆ˜í–‰í•˜ì§€ ëª»í•œë‹¤." }
  ]
}
"""

                    # ì§ˆë¬¸ë³„ë¡œ ë©”íŠ¸ë¦­ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
                    # session_stateì— ì €ì¥ (ë¦¬ë Œë”ë§ í›„ì—ë„ ìœ ì§€)
                    st.session_state.all_metrics = []
                    
                    for idx, q in enumerate(questions, 1):
                        question_order = q[1]
                        quality_attr = q[2]
                        question_text = q[3]
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        progress_placeholder.info(
                            f"ğŸ”„ ì§„í–‰ ì¤‘... ({idx}/{len(questions)}) Q{question_order}. {question_text[:40]}..."
                        )
                        
                        # ê° ì§ˆë¬¸ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
                        single_metric_prompt = f"""
ë‹¹ì‹ ì€ ISO/IEC 25010 ê¸°ë°˜ì˜ ì†Œí”„íŠ¸ì›¨ì–´ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´, í‰ê°€ì²™ë„ë³„ë¡œ í‰ê°€ìê°€ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” 'êµ¬ê°„ë³„ ì„¤ëª…'ì„ ìƒì„±í•˜ì„¸ìš”.

**í‰ê°€ ì²™ë„**
{scale_description}

**ì§ˆë¬¸**
Q{question_order}. [{quality_attr}] {question_text}

âš ï¸ ìƒì„± ê·œì¹™:
- í•­ìƒ ë†’ì€ ì ìˆ˜(ê¸ì •ì  í‰ê°€)ì—ì„œ ë‚®ì€ ì ìˆ˜(ë¶€ì •ì  í‰ê°€) ìˆœìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
- ê° scale_interpretations í•­ëª©ì€ ë°˜ë“œì‹œ ì•„ë˜ 3ê°œì˜ í‚¤ë¥¼ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
  1. "scale_order" (ì •ìˆ˜)
  2. "scale" (ì²™ë„ëª…)
  3. "description" (ë¬¸ì¥í˜• ì„¤ëª…)
- ì–´ë–¤ ê²½ìš°ì—ë„ "description"ì€ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”.
- JSON ê°ì²´ 1ê°œë§Œ ìƒì„±í•˜ì„¸ìš” (ë°°ì—´ ì•„ë‹˜).

{example_json}
"""
                        
                        # LLM í˜¸ì¶œ (ê° ì§ˆë¬¸ë³„)
                        response = client.chat.completions.create(
                            model=DEPLOYMENT_NAME,
                            messages=[
                                {"role": "system", "content": "ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
                                {"role": "user", "content": single_metric_prompt}
                            ],
                            temperature=0.3
                        )
                        
                        content = response.choices[0].message.content.strip()
                        
                        # JSON íŒŒì‹±
                        try:
                            metric_obj = json.loads(content)
                            st.session_state.all_metrics.append(metric_obj)
                        except json.JSONDecodeError:
                            st.error(f"âŒ Q{question_order} JSON íŒŒì‹± ì‹¤íŒ¨")
                            st.text(content)
                            st.stop()
                    
                    progress_placeholder.success(f"âœ… ëª¨ë“  ì§ˆë¬¸ì˜ ë©”íŠ¸ë¦­ ìƒì„± ì™„ë£Œ!")
                    st.session_state.metrics_generated = True

                except Exception as e:
                    progress_placeholder.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    with st.expander("ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸ ì •ë³´", expanded=True):
                        st.exception(e)
            
            # ë©”íŠ¸ë¦­ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ í‘œì‹œ (ë²„íŠ¼ ë°–ì—ì„œë„ ìœ ì§€)
            if st.session_state.metrics_generated and len(st.session_state.all_metrics) > 0:
                st.divider()
                st.markdown("### ğŸ“Š ìƒì„±ëœ ë©”íŠ¸ë¦­ í™•ì¸")
                for metric_info in st.session_state.all_metrics:
                    question_order = metric_info["question_order"]
                    qa = metric_info["quality_attribute"]
                    qtext = metric_info["question_text"]
                    with st.expander(f"**{question_order}**. [{qa}] {qtext}", expanded=False):
                        for scale_obj in sorted(metric_info["scale_interpretations"], key=lambda x: x["scale_order"], reverse=True):
                            desc = scale_obj.get("description", "(ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤)")
                            st.markdown(f"**{scale_obj['scale']}** : {desc}")

                st.divider()

                # ë©”íŠ¸ë¦­ ì €ì¥ ë²„íŠ¼ (ë²„íŠ¼ ë°–ì—ì„œ)
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥í•˜ê¸°", type="primary", use_container_width=True, key="save_metrics_outside"):
                        save_status = st.empty()
                        try:
                            conn = get_connection()
                            cur = conn.cursor()
                            
                            # metrics í…Œì´ë¸”ì— ì €ì¥
                            for idx, metric_info in enumerate(st.session_state.all_metrics, 1):
                                question_order = metric_info["question_order"]
                                
                                # í•´ë‹¹ question_orderë¥¼ ê°€ì§„ question_id ì°¾ê¸°
                                question_id = None
                                for q in questions:
                                    if q[1] == question_order:
                                        question_id = q[0]
                                        break
                                
                                if question_id:
                                    # scale_interpretationsë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                                    element_description = json.dumps(
                                        metric_info["scale_interpretations"],
                                        ensure_ascii=False
                                    )
                                    
                                    cur.execute("""
                                        INSERT INTO metrics 
                                        (survey_id, question_id, scale_type, element_description)
                                        VALUES (%s, %s, %s, %s)
                                    """, (selected_survey_id, question_id, selected_scale_type, element_description))
                                    
                                    save_status.info(f"ğŸ’¾ ì €ì¥ ì¤‘... ({idx}/{len(st.session_state.all_metrics)})")
                            
                            conn.commit()
                            cur.close()
                            conn.close()
                            
                            save_status.empty()
                            st.success("âœ… ë©”íŠ¸ë¦­ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.info("ğŸ‘‰ ë‹¤ìŒ: í‰ê°€ í”„ë ˆì„ì›Œí¬ ìƒì„±ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        except Exception as save_error:
                            st.error(f"âŒ ë©”íŠ¸ë¦­ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(save_error)}")
                            st.exception(save_error)
                
                with col2:
                    # ë©”íŠ¸ë¦­ JSON ë‹¤ìš´ë¡œë“œ
                    metrics_json = json.dumps(st.session_state.all_metrics, ensure_ascii=False, indent=2)
                    st.download_button(
                        label="ğŸ“¥ ë©”íŠ¸ë¦­ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (JSON)",
                        data=metrics_json,
                        file_name=f"metrics_{selected_project_name}.json",
                        mime="application/json",
                        use_container_width=True,
                        key="download_metrics_outside"
                    )

                st.divider()
        else:
            st.warning("âš ï¸ ì„ íƒëœ í”„ë¡œì íŠ¸ì— ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

# í•˜ë‹¨ ì •ë³´
st.divider()
st.markdown("""
<div style='text-align: center; color: gray; font-size: 0.9em;'>
    ISO/IEC 25010 ê¸°ë°˜ SW í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­ êµ¬ì„±<br>
    Powered by Azure OpenAI & Streamlit
</div>
""", unsafe_allow_html=True)
