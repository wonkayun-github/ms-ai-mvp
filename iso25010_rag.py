import streamlit as st
import os, uuid, time
from dotenv import load_dotenv
from azure.storage.blob import BlobServiceClient
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex,
    SearchableField,
    SimpleField,
    SearchField,
    SearchFieldDataType,
    VectorSearch,
    VectorSearchProfile,
    HnswAlgorithmConfiguration,
)
from azure.core.credentials import AzureKeyCredential
from openai import AzureOpenAI

# === í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
load_dotenv()

# === Azure í™˜ê²½ë³€ìˆ˜ ===
# OpenAI
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION", "2024-12-01-preview")
DEPLOYMENT_NAME = os.getenv("DEPLOYMENT_NAME", "gpt-4.1-mini")
DEPLOYMENT_EMBEDDING_NAME = os.getenv("DEPLOYMENT_EMBEDDING_NAME", "text-embedding-3-small")

# AI Search
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME", "iso25010-index")

# Blob Storage
AZURE_STORAGE_ACCOUNT_NAME = os.getenv("AZURE_STORAGE_ACCOUNT_NAME")
AZURE_STORAGE_ACCOUNT_KEY = os.getenv("AZURE_STORAGE_ACCOUNT_KEY")
AZURE_STORAGE_CONTAINER_NAME = os.getenv("AZURE_STORAGE_CONTAINER_NAME", "docs")

# === í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ===
blob_service_client = BlobServiceClient(
    account_url=f"https://{AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net",
    credential=AZURE_STORAGE_ACCOUNT_KEY
)

search_endpoint = AZURE_SEARCH_ENDPOINT
search_key = AZURE_SEARCH_API_KEY
index_name = AZURE_SEARCH_INDEX_NAME

openai_client = AzureOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=OPENAI_API_VERSION
)

# === Blob ì»¨í…Œì´ë„ˆ ë³´ì¥ ===
try:
    blob_service_client.create_container(AZURE_STORAGE_CONTAINER_NAME)
except Exception:
    pass

# === Streamlit í˜ì´ì§€ ì„¤ì • ===
st.set_page_config(page_title="RAG ë°ì´í„° êµ¬ì„±", layout="wide")
st.title("ğŸ“˜ RAG ë°ì´í„° êµ¬ì„±")

# --- 1ï¸âƒ£ ë¬¸ì„œ ì—…ë¡œë“œ ---
st.markdown("#### ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("TXT í˜•ì‹ì˜ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["txt"], label_visibility="collapsed")

if uploaded_file:
    blob_client = blob_service_client.get_blob_client(container=AZURE_STORAGE_CONTAINER_NAME, blob=uploaded_file.name)
    blob_client.upload_blob(uploaded_file.getvalue(), overwrite=True)
    st.success(f"âœ… '{uploaded_file.name}' ì—…ë¡œë“œ ì™„ë£Œ!")

# --- 2ï¸âƒ£ ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡ ---
st.markdown("#### ğŸ“‚ ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡")
container_client = blob_service_client.get_container_client(AZURE_STORAGE_CONTAINER_NAME)
blobs = list(container_client.list_blobs())

if not blobs:
    st.info("í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    filenames = [blob.name for blob in blobs]
    selected_file = st.selectbox("ì¸ë±ì‹±í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", filenames)
    col1, col2 = st.columns([1, 0.2])
    with col1:
        index_btn = st.button("ğŸ” ì„ íƒ íŒŒì¼ ì¸ë±ì‹± ì‹œì‘")
    with col2:
        if st.button("ğŸ—‘ íŒŒì¼ ì‚­ì œ"):
            blob_client = container_client.get_blob_client(selected_file)
            blob_client.delete_blob()
            st.warning(f"'{selected_file}' ì‚­ì œ ì™„ë£Œ!")
            st.rerun()

# --- 3ï¸âƒ£ ì¸ë±ì‹± ---
if "indexed_files" not in st.session_state:
    st.session_state.indexed_files = set()

if 'index_btn' in locals() and index_btn:
    st.markdown("### âš™ï¸ ì¸ë±ì‹± ì§„í–‰ ì¤‘...")

    index_client = SearchIndexClient(endpoint=search_endpoint, credential=AzureKeyCredential(search_key))

    # === ìµœì‹  ìŠ¤í™ ë°˜ì˜ëœ í•„ë“œ ì •ì˜ ===
    fields = [
        SimpleField(name="id", type=SearchFieldDataType.String, key=True),
        SearchableField(name="content", type=SearchFieldDataType.String),
        SimpleField(name="source", type=SearchFieldDataType.String),
        SearchField(
            name="embedding",
            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
            searchable=True,
            vector_search_dimensions=1536,
            vector_search_profile_name="vector-profile"
        ),
    ]

    # === Vector Search êµ¬ì„± ===
    vector_search = VectorSearch(
        algorithms=[HnswAlgorithmConfiguration(name="hnsw-config")],
        profiles=[VectorSearchProfile(name="vector-profile", algorithm_configuration_name="hnsw-config")]
    )

    # === ì¸ë±ìŠ¤ ìƒì„± ===
    index = SearchIndex(
        name=index_name,
        fields=fields,
        vector_search=vector_search
    )

    index_client.create_or_update_index(index)

    # === ë¬¸ì„œ ì½ê¸° ë° ì„ë² ë”© ì²˜ë¦¬ ===
    blob_data = container_client.download_blob(selected_file).readall().decode("utf-8")
    chunks = [blob_data[i:i+2000] for i in range(0, len(blob_data), 2000)]
    search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=AzureKeyCredential(search_key))

    progress = st.progress(0)
    docs = []
    for i, chunk in enumerate(chunks):
        embedding = openai_client.embeddings.create(
            model=DEPLOYMENT_EMBEDDING_NAME,
            input=chunk
        ).data[0].embedding

        docs.append({
            "id": str(uuid.uuid4()),
            "content": chunk,
            "source": selected_file,
            "embedding": embedding
        })
        progress.progress((i + 1) / len(chunks))
        time.sleep(0.05)

    search_client.upload_documents(docs)
    st.success(f"âœ… {selected_file} ì¸ë±ì‹± ì™„ë£Œ! ({len(docs)}ê°œ ì„¹ì…˜)")
    st.session_state.indexed_files.add(selected_file)

# --- 4ï¸âƒ£ ì§ˆì˜ì‘ë‹µ (RAG) ---
st.markdown("#### ğŸ’¬ ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸")
query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ISO 25010ì—ì„œ ê¸°ëŠ¥ì  ì í•©ì„±ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
if st.button("ğŸ” ë‹µë³€ ìƒì„±"):
    if not query:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ğŸ” ê²€ìƒ‰ ë° LLM ì‘ë‹µ ìƒì„± ì¤‘..."):
            search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=AzureKeyCredential(search_key))
            embedding = openai_client.embeddings.create(
                model=DEPLOYMENT_EMBEDDING_NAME,
                input=query
            ).data[0].embedding

            results = search_client.search(
                search_text=None,
                vector_queries=[{
                    "kind": "vector",
                    "vector": embedding,
                    "fields": "embedding",
                    "k": 3
                }],
                select=["content", "source"]
            )

            sources, context_chunks = [], []
            for doc in results:
                context_chunks.append(doc["content"])
                sources.append(doc["source"])

            context = "\n\n".join(context_chunks)
            prompt = f"""
            ë‹¤ìŒì€ ISO 25010 ë¬¸ì„œì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤:

            {context}

            ì§ˆë¬¸: {query}
            ISO 25010 ê¸°ì¤€ì— ë”°ë¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """

            response = openai_client.chat.completions.create(
                model=DEPLOYMENT_NAME,
                messages=[{"role": "user", "content": prompt}]
            )
            answer = response.choices[0].message.content

        st.subheader("ğŸ§  ë‹µë³€")
        st.write(answer)

        with st.expander("ğŸ“– ì°¸ì¡°ëœ ë¬¸ì„œ"):
            for src in set(sources):
                st.markdown(f"- `{src}`")
